{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study\n",
    "#### Author: Li Tang\n",
    "#### Date: October 8, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Map Area\n",
    "#### Boston, Massachusetts, USA\n",
    "I am using the OpenStreet data of Boston Massachusetts area from mapzen.com https://mapzen.com/data/metro-extracts/metro/boston_massachusetts/. I would like to take this oppotunity to explore Bonston area. The data format is XML. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identifying Problems in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output from audit.py script will be analyzed to visualize any unsual street names and postal codes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Some Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Some abbreviated street types, for example, 'St.', 'St', 'st', 'ST', and 'ST'. \n",
    "2. A few inconsistent postal codes, like 'MA 02118' and '02118-0239'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Correct inconsistent street names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the project is to fix the street types as below: \n",
    "\n",
    "          {\n",
    "           \"St\": \"Street\",\n",
    "           \"st\": \"Street\",\n",
    "           \"Street.\": \"Street\", \n",
    "           \"street\": \"Street\",\n",
    "           \"St.\": \"Street\",\n",
    "           \"St,\": \"Street\", \n",
    "           \"ST\": \"Street\",\n",
    "           \"Rd.\": \"Road\", \n",
    "           \"Ave\": \"Avenue\", \n",
    "           \"Ave.\": \"Avenue\",\n",
    "           \"Pkwy\": \"Parkway\", \n",
    "           \"rd.\": \"Road\", \n",
    "           \"Ct\": \"Court\",  \n",
    "           \"Dr\": \"Drive\", \n",
    "           \"Rd\": \"Road\", \n",
    "           \"Hwy\": \"Highway\", \n",
    "           \"Sq.\": \"Square\"\n",
    "           }\n",
    "\n",
    "The procedure in detail is demonstrated in audit_street.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly stated: \n",
    "1. Create a list of expected street types that do not need to be cleaned.\n",
    "2. The function \"audit_street_type\" collects the last words in the \"street_name\" strings, if they are not within the expected list, then stores them in the dictionary \"street_types\". This will allow me to see the nonuniform and abbreviated street types being used and give me a better sense of the data in the big picture.\n",
    "3. The \"is_street_name\" function looks for tags that specify street names (k=\"addr:street\").\n",
    "4. The \"audit\" function returns a dictionary that match the above function conditions.\n",
    "5. The update_name function takes an old name to mapping dictionary, and update to a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Correct postal codes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Boston area postal codes begin with \"021,022, and 024\". Some of their formats are 5 digits, and some are 9 digits, and some even begin with state characters. \n",
    "2. The leading and trailing characters other than the main 5 digits will be dropped. After cleaning, 'MA 02118' will be fixed to '02118' and '02118-0239' will become '02118'. The detailed procedure is illustrated in audit_postcode.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CSV File Generation for SQL Database Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements in the OSM XML file will be parsed, transforming the document data into the tabular format. The final purpose is to prepare a .csv files that are easy to be imported to a SQL database. The detailed procedure is shown in data_process.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SQL DataBase and Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Create SQL Database and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "sqlite_file = \"project.db\"\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS nodes')\n",
    "cur.execute('''\n",
    "   Create Table nodes(id INTEGER, lat REAL, lon REAL, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS ways')\n",
    "cur.execute('''\n",
    "   Create Table ways(id INTEGER, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS nodes_tags')\n",
    "cur.execute('''\n",
    "   Create Table nodes_tags(id INTEGER, key TEXT, value TEXT, type TEXT)\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS ways_tags')\n",
    "cur.execute('''\n",
    "   Create Table ways_tags(id INTEGER, key TEXT, value TEXT, type TEXT)\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS ways_nodes')\n",
    "cur.execute('''\n",
    "   Create Table ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)\n",
    "''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Insert Data from CSV Files into SQL Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2879420>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "with open('nodes.csv', 'rb') as fin_nodes:\n",
    "    dr = csv.DictReader(fin_nodes) \n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'].decode('utf8'), i['uid'],\n",
    "             i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "# insert data to table\n",
    "cur.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version,changeset,timestamp) VALUES(?, ?, ?, ?, ?, ?, ?, ?);\", to_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2879420>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "with open('ways.csv', 'rb') as fin_ways:\n",
    "    dr = csv.DictReader(fin_ways) \n",
    "    to_db = [(i['id'], i['user'].decode('utf8'), i['uid'],\n",
    "             i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "# insert data to table\n",
    "cur.executemany(\"INSERT INTO ways(id,user, uid, version,changeset,timestamp) VALUES(?, ?, ?, ?, ?, ?);\", to_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2879420>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "with open('nodes_tags.csv', 'rb') as fin_nodes_tags:\n",
    "    dr = csv.DictReader(fin_nodes_tags) \n",
    "    to_db = [(i['id'], i['key'].decode('utf8'), i['value'].decode('utf8'),\n",
    "             i['type'].decode('utf8')) for i in dr]\n",
    "\n",
    "# insert data to table\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id,key, value, type) VALUES(?, ?, ?, ?);\", to_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2879420>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "with open('ways_tags.csv', 'rb') as fin_ways_tags:\n",
    "    dr = csv.DictReader(fin_ways_tags) \n",
    "    to_db = [(i['id'], i['key'].decode('utf8'), i['value'].decode('utf8'),\n",
    "             i['type'].decode('utf8')) for i in dr]\n",
    "# insert data to table\n",
    "cur.executemany(\"INSERT INTO ways_tags(id, key, value,type) VALUES(?, ?, ?, ?);\", to_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2879420>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "with open('ways_nodes.csv', 'rb') as fin_ways_nodes:\n",
    "    dr = csv.DictReader(fin_ways_nodes) \n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "\n",
    "# insert data to table\n",
    "cur.executemany(\"INSERT INTO ways_nodes(id,node_id,position) VALUES(?, ?, ?);\", to_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Summary statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boston.osm file is 438.811272 MB\n",
      "The project.db file is 255.932416 MB\n",
      "The nodes.csv file is 160.95605 MB\n",
      "The nodes_tags.csv file is 17.527426 MB\n",
      "The ways.csv file is 21.045341 MB\n",
      "The ways_tags.csv is 23.00255 MB\n",
      "The ways_nodes.csv is 55.58002 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('The boston.osm file is {} MB'.format(os.path.getsize('boston.osm')/1.0e6))\n",
    "print('The project.db file is {} MB'.format(os.path.getsize('project.db')/1.0e6))\n",
    "print('The nodes.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print('The nodes_tags.csv file is {} MB'.format(os.path.getsize('nodes_tags.csv')/1.0e6))\n",
    "print('The ways.csv file is {} MB'.format(os.path.getsize('ways.csv')/1.0e6))\n",
    "print('The ways_tags.csv is {} MB'.format(os.path.getsize('ways_tags.csv')/1.0e6))\n",
    "print('The ways_nodes.csv is {} MB'.format(os.path.getsize('ways_nodes.csv')/1.0e6)) # Convert from bytes to MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Data Inquiry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1952878,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM nodes;\")\n",
    "print(cur.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(311076,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM ways;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1421,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'crschmidt', 1195006),\n",
      " (u'jremillard-massgis', 428633),\n",
      " (u'wambag', 111175),\n",
      " (u'OceanVortex', 90950),\n",
      " (u'morganwahl', 67049),\n",
      " (u'ryebread', 65963),\n",
      " (u'MassGIS Import', 58553),\n",
      " (u'ingalls_imports', 32453),\n",
      " (u'Ahlzen', 28321),\n",
      " (u'mapper999', 14697)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute(\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Number of Starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(64,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM nodes_tags WHERE value LIKE '%Starbucks%';\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Tourism Related Categories Descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'hotel', 103),\n",
      " (u'museum', 60),\n",
      " (u'artwork', 58),\n",
      " (u'attraction', 38),\n",
      " (u'viewpoint', 33),\n",
      " (u'information', 27),\n",
      " (u'picnic_site', 26),\n",
      " (u'guest_house', 9),\n",
      " (u'hostel', 5),\n",
      " (u'motel', 3),\n",
      " (u'aquarium', 2),\n",
      " (u'chalet', 2),\n",
      " (u'apartment', 1),\n",
      " (u'gallery', 1),\n",
      " (u'theme_park', 1),\n",
      " (u'zoo', 1)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute (\"SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION ALL \\\n",
    "             SELECT * FROM ways_tags) tags \\\n",
    "             WHERE tags.key LIKE '%tourism'\\\n",
    "             GROUP BY tags.value \\\n",
    "             ORDER BY count DESC;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Further Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Restaurants in each city descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Boston', 55),\n",
      " (u'Cambridge', 51),\n",
      " (u'Somerville', 19),\n",
      " (u'Brookline', 10),\n",
      " (u'Allston', 5),\n",
      " (u'East Boston', 5),\n",
      " (u'Brookline, MA', 4),\n",
      " (u'Chelsea', 4),\n",
      " (u'Arlington', 3),\n",
      " (u'Medford', 3),\n",
      " (u'Watertown', 3),\n",
      " (u'Arlington. MA', 2),\n",
      " (u'Boston, MA', 2),\n",
      " (u'Brighton', 2),\n",
      " (u'Charlestown', 2),\n",
      " (u'Chestnut Hill', 2),\n",
      " (u'Jamaica Plain', 2),\n",
      " (u'Malden', 2),\n",
      " (u'2067 Massachusetts Avenue', 1),\n",
      " (u'Arlington, MA', 1),\n",
      " (u'Cambridge, MA', 1),\n",
      " (u'Cambridge, Massachusetts', 1),\n",
      " (u'Everett', 1),\n",
      " (u'Quincy', 1),\n",
      " (u'Watertown, MA', 1),\n",
      " (u'boston', 1),\n",
      " (u'somerville', 1),\n",
      " (u'winthrop', 1)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute(\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "            FROM nodes_tags WHERE value = 'restaurant') i ON nodes_tags.id = i.id WHERE nodes_tags.key = 'city'\\\n",
    "            GROUP BY nodes_tags.value ORDER BY num DESC;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Most Popular Fast Food Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u\"Dunkin' Donuts\", 13),\n",
      " (u'Subway', 12),\n",
      " (u\"McDonald's\", 9),\n",
      " (u'Burger King', 8),\n",
      " (u\"Wendy's\", 5)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "             FROM nodes_tags WHERE value='fast_food') i ON nodes_tags.id=i.id WHERE nodes_tags.key='name' \\\n",
    "             GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 5;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Cafe Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Starbucks', 48),\n",
      " (u\"Dunkin' Donuts\", 45),\n",
      " (u'Au Bon Pain', 7),\n",
      " (u'Dunkin Donuts', 6),\n",
      " (u\"Peet's Coffee\", 5)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "             FROM nodes_tags WHERE value='cafe') i ON nodes_tags.id=i.id WHERE nodes_tags.key='name' \\\n",
    "             GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 5;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above review, there are only 103 hotels in Boston. A quick search on hotel.com gives me a result of 597 results. OpenStreetMap should encourage hotels, restaurants and other local business owners to publish on OSM, and edit their own content to make it more accurate and make it available for everyone to benefit from.Parks, schools, hotels, restaurants and other local businesses should be able to update and edit their own data on OSM, to ensure the accuracy and completeness. There are potential to extend OpenStreetMap to include travel, walking and biking tour information, user reviews of establishments, local public transit etc. If more people use it, more people adding data, and this makes the maps better for everyone. This could expand OpenStreetMap's user base, and become more consumer focused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Givin that there're hundreds of contributors for this map, we could expect a great numbers of human errors in this project. A srtuctured input form is strongly recommended so that everyone can input the same data format to reduce the error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
